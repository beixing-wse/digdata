# 常用脚本文件

## zookeeper

```shell
#! /bin/bash
case $1 in
"start"){
	for i in hadoop102 hadoop103 ha::doop104
	do
		ssh $i "source /etc/profile && /opt/module/zookeeper-3.4.10/bin/zkServer.sh start"
	done
};;
"stop"){
	for i in hadoop102 hadoop103 hadoop104
	do
		ssh $i "/opt/module/zookeeper-3.4.10/bin/zkServer.sh stop"
	done
};;
"status"){
	for i in hadoop102 hadoop103 hadoop104
	do
		ssh $i "/opt/module/zookeeper-3.4.10/bin/zkServer.sh status"
	done
};;
esac
```

## hadoop

```shell
#!/bin/bash
case $1 in
"start"){
	
	echo "================     正在启动HDFS                    ==========="
	ssh hadoop102 'start-dfs.sh'
	echo "================     正在启动YARN                    ==========="
	ssh hadoop103 'start-yarn.sh'
	echo "================     正在开启JobHistoryServer        ==========="
	ssh hadoop102 'mapred --daemon start historyserver'
	
};;

"stop"){
	
	
	echo "================     正在关闭YARN                    ==========="
	ssh hadoop103 '/opt/module/hadoop-2.7.2/sbin/stop-yarn.sh'
	echo "================     正在关闭HDFS                    ==========="
	ssh hadoop102 '/opt/module/hadoop-2.7.2/sbin/stop-dfs.sh'
	echo "================     正在关闭JobHistoryServer        ==========="
	ssh hadoop102 'mapred --daemon stop historyserver'
};;

esac

```

## kafka

```shell
#!/bin/bash
case $1 in
"start"){
	
	for i in atguigu@hadoop102 atguigu@hadoop103 atguigu@hadoop104
	do
		echo "*************$i************"
		ssh $i "source /etc/profile && /opt/module/kafka/bin/kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties"
	done
};;

"stop"){
	
	for i in atguigu@hadoop102 atguigu@hadoop103 atguigu@hadoop104
	do
		echo "*************$i************"
		ssh $i "source /etc/profile && /opt/module/kafka/bin/kafka-server-stop.sh -daemon /opt/module/kafka/config/server.properties"
	done
};;

esac
```

## jps

```shell
for i in atguigu@hadoop102 atguigu@hadoop103 atguigu@hadoop104
do
	echo "===============$i============================="
	ssh $i "jps" | grep -v Jps
done
```

## xsync

```shell
#!/bin/bash
#1 获取输入参数个数，如果没有参数，直接退出
pcount=$#
if((pcount==0)); then
echo no args;
exit;
fi

#2 获取文件名称
p1=$1
fname=`basename $p1`
echo fname=$fname

#3 获取上级目录到绝对路径
pdir=`cd -P $(dirname $p1); pwd`
echo pdir=$pdir

#4 获取当前用户名称
user=`whoami`

#5 循环
for((host=103; host<105; host++)); do
        echo ------------------- hadoop$host --------------
        rsync -rvl $pdir/$fname $user@hadoop$host:$pdir
done
```

