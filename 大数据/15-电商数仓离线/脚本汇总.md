# 脚本汇总

## xsync

```shell
#!/bin/bash
#1 获取输入参数个数，如果没有参数，直接退出
pcount=$#
if((pcount==0)); then
	echo no args;
	exit;
fi

#2 获取文件名称
p1=$1
fname=`basename $p1`
echo fname=$fname

#3 获取上级目录到绝对路径
pdir=`cd -P $(dirname $p1); pwd`
echo pdir=$pdir

#4 获取当前用户名称
user=`whoami`

#5 循环
for((host=103; host<105; host++)); do
        echo ------------------- hadoop$host --------------
        rsync -rvl $pdir/$fname $user@hadoop$host:$pdir
done
```

xcall.sh

```shell
#! /bin/bash
for i in hadoop102 hadoop103 hadoop104
do
    echo --------- $i ----------
    ssh $i "$*"
done

```

## zk.sh

```shell
#!/bin/bash

case $1 in
"start"){
    for i in hadoop102 hadoop103 hadoop104
    do
        echo "------------- $i -------------"
        ssh $i "/opt/module/zookeeper-3.5.7/bin/zkServer.sh start"
    done 
};;
"stop"){
    for i in hadoop102 hadoop103 hadoop104
    do
        echo "------------- $i -------------"
        ssh $i "/opt/module/zookeeper-3.5.7/bin/zkServer.sh stop"
    done
};;
"status"){
    for i in hadoop102 hadoop103 hadoop104
    do
        echo "------------- $i -------------"
        ssh $i "/opt/module/zookeeper-3.5.7/bin/zkServer.sh status"
    done
};;
esac
```

## ha.sh

```shell
#!/bin/bash

case $1 in
"start"){
	echo "================     正在启动HDFS                    ==========="
	ssh hadoop102 'start-dfs.sh'
	echo "================     正在启动YARN                    ==========="
	ssh hadoop103 'start-yarn.sh'
	echo "================     正在开启JobHistoryServer        ==========="
	ssh hadoop102 'mapred --daemon start historyserver'
};;

"stop"){
	echo "================     正在关闭YARN                    ==========="
	ssh hadoop103 'stop-yarn.sh'
	echo "================     正在关闭HDFS                    ==========="
	ssh hadoop102 'stop-dfs.sh'
	echo "================     正在关闭JobHistoryServer        ==========="
        ssh hadoop102 'mapred --daemon stop historyserver'
};;
esac

```

## log.sh

```shell
#! /bin/bash

for i in hadoop102 hadoop103 
do
	ssh $i "java -jar /opt/module/log-collector-1.0-SNAPSHOT-jar-with-dependencies.jar $1 $2 >/dev/null 2>&1 &"
done
```

## f1.sh

```shell
#! /bin/bash

case $1 in
"start"){
        for i in hadoop102 hadoop103
        do
                echo " --------启动 $i 采集flume-------"
                ssh $i "nohup /opt/module/flume/bin/flume-ng agent --conf-file /opt/module/flume/conf/file-flume-kafka.conf --name a1 -Dflume.root.logger=INFO,LOGFILE >/opt/module/flume/test1 2>&1  &"
        done
};;	
"stop"){
        for i in hadoop102 hadoop103
        do
                echo " --------停止 $i 采集flume-------"
                ssh $i "ps -ef | grep file-flume-kafka | grep -v grep |awk  '{print \$2}' | xargs -n1 kill -9 "
        done

};;
esac
```

## kf.sh

```shell
#! /bin/bash

case $1 in
"start"){
    for i in hadoop102 hadoop103 hadoop104
    do
        echo " --------启动 $i Kafka-------"
        ssh $i "/opt/module/kafka/bin/kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties"
    done
};;
"stop"){
    for i in hadoop102 hadoop103 hadoop104
    do
        echo " --------停止 $i Kafka-------"
        ssh $i "/opt/module/kafka/bin/kafka-server-stop.sh stop"
    done
};;
esac
```



## f2.sh

```shell
#! /bin/bash

case $1 in
"start"){
        for i in hadoop104
        do
                echo " --------启动 $i 消费flume-------"
                ssh $i "nohup /opt/module/flume/bin/flume-ng agent --conf-file /opt/module/flume/conf/kafka-flume-hdfs.conf --name a1 -Dflume.root.logger=INFO,LOGFILE >/opt/module/flume/log.txt   2>&1 &"
        done
};;
"stop"){
        for i in hadoop104
        do
                echo " --------停止 $i 消费flume-------"
                ssh $i "ps -ef | grep kafka-flume-hdfs | grep -v grep |awk '{print \$2}' | xargs -n1 kill"
        done

};;
esac
```



## cluster.sh

```shell
#! /bin/bash

case $1 in
"start"){
	echo " -------- 启动 集群 -------"

	echo " -------- 启动 hadoop集群 -------"
	/opt/module/hadoop-3.1.3/sbin/start-dfs.sh 
	ssh hadoop103 "/opt/module/hadoop-3.1.3/sbin/start-yarn.sh"
	#启动 Zookeeper集群
	zk.sh start
sleep 4s;

	#启动 Flume采集集群
	f1.sh start
	#启动 Kafka采集集群
	kf.sh start
sleep 6s;

	#启动 Flume消费集群
	f2.sh start
};;

"stop"){
    echo " -------- 停止 集群 -------"
    
    #停止 Flume消费集群
	f2.sh stop
	#停止 Kafka采集集群
	kf.sh stop
    sleep 6s;
	#停止 Flume采集集群
	f1.sh stop
	#停止 Zookeeper集群
	zk.sh stop
	echo " -------- 停止 hadoop集群 -------"
	ssh hadoop103 "/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh"
	/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh 
};;
esac
```

